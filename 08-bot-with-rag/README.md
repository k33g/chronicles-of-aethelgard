# Bot NPC + RAG
> Retrieval Augmented Generation

Cet exemple est √† titre √©ducatif. Nous ne l'utiliserons pas pour le "jeu" d√©finitif.

Mais cette technique peut √™tre utile avec des petits LLM qui ne savent pas utiliser correctement des "gros contextes".

Cette fois nous allons travailler avec 2 mod√®les:

- `qwen2.5:0.5b`
- `snowflake-arctic-embed:33m`

Le 2√®me LLM sert √† g√©n√©rer des embeddings üòÆü§î

- [Embeddings ?](docs/01-embeddings.md)
- [RAG ?](docs/02-rag.drawio)
- [Calcul de distance ?](docs/03-distance.md)

Nous avons donc 2 programmes:

## `chunking_test.go` pour g√©n√©rer les chunks

[Le code](chunking_test.go)


## `main.go` pour la compl√©tion avec recherche de similarit√©

[Le code](main.go)



## Que font le üê≥ compose file & le Dockerfile ?

- [Le üê≥ compose file](compose.yml) 
- [Dockerfile](Dockerfile)

## Lancer l'application

```bash
docker compose up --watch
```

## üöß Travaillez un peu

On va juste se contenter d'ex√©cuter les codes


## Testez les services (au moins un des services)

### Avec curl

- `query-1.sh`
- `query-2.sh`
- `query-3.sh`
- `query-4.sh`

> Bien s√ªr, adaptez les requ√™te (num√©ro de port HTTP par exemple)

### Si vous n'avez pas curl

```bash
docker run --rm --network host curlimages/curl:8.6.0 \
    --silent --no-buffer "http://localhost:5051/api/chat" \
    -H "Content-Type: application/json" \
    -d '{"question":"What is your name?"}'
```

etc ...

## Questions ?

## Quittez Docker Compose

[README](../README.md)