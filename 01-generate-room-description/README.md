# G√©n√©rer des descriptions de salles


<!-- TODO: √† re √©crire -->

```bash
docker compose up --watch
```



Il y a plusieurs fa√ßons de lancer le programme.

## Si Ollama et Go sont install√©s en local

dans le fichier `.env`, vous devez avoir:

```bash
OLLAMA_HOST=http://localhost:11434
LLM=qwen2.5:0.5b
```

Et vous lancez le programme avec:
```bash
go run main.go
```

## Si Ollama et Go sont install√©s dans des containers

dans le fichier `.env`, vous devez avoir:

```bash
OLLAMA_HOST=http://ollama-service:11434
LLM=qwen2.5:0.5b
```

Et vous lancez le programme avec:
```bash
docker compose up
```

Vous pouvez voir les r√©sultats avec:
```bash
docker compose logs generate-description
```

## Si Ollama est install√© en local et Go dans un container

Il est possible de "contacter" Ollama avec les param√®tres suivants:

```bash
OLLAMA_HOST=http://host.docker.internal:11434
LLM=qwen2.5:0.5b
```

## Autre option : Devcontainer

<üöß work in progress>


## Prompting

- Essayer d'autres prompts
- Jouer aussi avec les settings (temperature)